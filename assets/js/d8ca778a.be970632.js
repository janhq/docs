"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[5488],{69564:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>t,contentTitle:()=>i,default:()=>m,frontMatter:()=>a,metadata:()=>s,toc:()=>d});var r=o(74848),l=o(28453);const a={title:"Models",description:"Jan is a ChatGPT-alternative that runs on your own computer, with a local API server.",keywords:["Jan","Customizable Intelligence","LLM","local AI","privacy focus","free and open source","private and offline","conversational AI","no-subscription fee","large language models"]},i=void 0,s={id:"developer/framework/engineering/models",title:"Models",description:"Jan is a ChatGPT-alternative that runs on your own computer, with a local API server.",source:"@site/docs/developer/05-framework/03-engineering/models.md",sourceDirName:"developer/05-framework/03-engineering",slug:"/developer/framework/engineering/models",permalink:"/developer/framework/engineering/models",draft:!1,unlisted:!1,editUrl:"https://github.com/janhq/docs/tree/main/docs/developer/05-framework/03-engineering/models.md",tags:[],version:"current",lastUpdatedBy:"Nicole Zhu",lastUpdatedAt:1712027706,formattedLastUpdatedAt:"Apr 2, 2024",frontMatter:{title:"Models",description:"Jan is a ChatGPT-alternative that runs on your own computer, with a local API server.",keywords:["Jan","Customizable Intelligence","LLM","local AI","privacy focus","free and open source","private and offline","conversational AI","no-subscription fee","large language models"]},sidebar:"developerSidebar",previous:{title:"Messages",permalink:"/developer/framework/engineering/messages"},next:{title:"Threads",permalink:"/developer/framework/engineering/threads"}},t={},d=[{value:"Overview",id:"overview",level:2},{value:"Folder Structure",id:"folder-structure",level:2},{value:"<code>model.json</code>",id:"modeljson",level:2},{value:"Example",id:"example",level:3},{value:"API Reference",id:"api-reference",level:2},{value:"Importing Models",id:"importing-models",level:2}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",ul:"ul",...(0,l.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.admonition,{type:"caution",children:(0,r.jsx)(n.p,{children:"This is currently under development."})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"In Jan, models are primary entities with the following capabilities:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Users can import, configure, and run models locally."}),"\n",(0,r.jsxs)(n.li,{children:["An ",(0,r.jsx)(n.a,{href:"https://platform.openai.com/docs/api-reference/models",children:"OpenAI Model API"})," compatible endpoint at ",(0,r.jsx)(n.code,{children:"localhost:1337/v1/models"}),"."]}),"\n",(0,r.jsxs)(n.li,{children:["Supported model formats: ",(0,r.jsx)(n.code,{children:"ggufv3"}),", and more."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"folder-structure",children:"Folder Structure"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Models are stored in the ",(0,r.jsx)(n.code,{children:"/models"})," folder."]}),"\n",(0,r.jsx)(n.li,{children:"Models are organized by individual folders, each containing the binaries and configurations needed to run the model. This makes for easy packaging and sharing."}),"\n",(0,r.jsxs)(n.li,{children:["Model folder names are unique and used as ",(0,r.jsx)(n.code,{children:"model_id"})," default values."]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",children:"jan/                               # Jan root folder\n  models/\n    llama2-70b-q4_k_m/             # Example: standard GGUF model\n        model.json\n        model-binary-1.gguf\n    mistral-7b-gguf-q3_k_l/        # Example: quantizations are separate folders\n        model.json\n        mistral-7b-q3-K-L.gguf\n    mistral-7b-gguf-q8_k_m/        # Example: quantizations are separate folders\n        model.json\n        mistral-7b-q8_k_k.gguf\n    llava-ggml-Q5/                 # Example: model with many partitions\n        model.json\n        mmprj.bin\n        model_q5.ggml\n"})}),"\n",(0,r.jsx)(n.h2,{id:"modeljson",children:(0,r.jsx)(n.code,{children:"model.json"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Each ",(0,r.jsx)(n.code,{children:"model"})," folder contains a ",(0,r.jsx)(n.code,{children:"model.json"})," file, which is a representation of a model."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"model.json"})," contains metadata and default parameters used to run a model."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example",children:"Example"}),"\n",(0,r.jsxs)(n.p,{children:["Here's a standard example ",(0,r.jsx)(n.code,{children:"model.json"})," for a GGUF model."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-js",children:'{\n  "id": "zephyr-7b",        // Defaults to foldername\n  "object": "model",        // Defaults to "model"\n  "sources": [\n    {\n      "filename": "zephyr-7b-beta.Q4_K_M.gguf",\n      "url": "https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/blob/main/zephyr-7b-beta.Q4_K_M.gguf"\n    }\n  ],\n  "name": "Zephyr 7B",      // Defaults to foldername\n  "owned_by": "you",        // Defaults to "you"\n  "version": "1",           // Defaults to 1\n  "created": 1231231,       // Defaults to file creation time\n  "description": null,      // Defaults to null\n  "format": "ggufv3",       // Defaults to "ggufv3"\n  "engine": "nitro",        // engine_id specified in jan/engine folder\n  "engine_parameters": {\n    // Engine parameters inside model.json can override\n    "ctx_len": 4096,        // the value inside the base engine.json\n    "ngl": 100,\n    "embedding": true,\n    "n_parallel": 4\n  },\n  "model_parameters": {\n    // Models are called parameters\n    "stream": true,\n    "max_tokens": 4096,\n    "stop": ["<endofstring>"], // This usually can be left blank, only used with specific need from model author\n    "frequency_penalty": 0,\n    "presence_penalty": 0,\n    "temperature": 0.7,\n    "top_p": 0.95\n  },\n  "metadata": {},           // Defaults to {}\n  "assets": [\n    // Defaults to current dir\n    "file://.../zephyr-7b-q4_k_m.bin"\n  ]\n}\n'})}),"\n",(0,r.jsxs)(n.p,{children:["The engine parameters in the example can be found at: ",(0,r.jsx)(n.a,{href:"https://nitro.jan.ai/features/load-unload#table-of-parameters",children:"Nitro's model settings"})]}),"\n",(0,r.jsxs)(n.p,{children:["The model parameters in the example can be found at: ",(0,r.jsx)(n.a,{href:"https://nitro.jan.ai/api-reference#tag/Chat-Completion",children:"Nitro's model parameters"})]}),"\n",(0,r.jsx)(n.h2,{id:"api-reference",children:"API Reference"}),"\n",(0,r.jsxs)(n.p,{children:["Jan's Model API is compatible with ",(0,r.jsx)(n.a,{href:"https://platform.openai.com/docs/api-reference/models",children:"OpenAI's Models API"}),", with additional methods for managing and running models locally."]}),"\n",(0,r.jsxs)(n.p,{children:["See ",(0,r.jsx)(n.a,{href:"https://jan.ai/api-reference#tag/Models",children:"Jan Models API"}),"."]}),"\n",(0,r.jsx)(n.h2,{id:"importing-models",children:"Importing Models"}),"\n",(0,r.jsx)(n.admonition,{type:"caution",children:(0,r.jsx)(n.p,{children:"This is currently under development."})}),"\n",(0,r.jsxs)(n.p,{children:["You can import a model by dragging the model binary or gguf file into the ",(0,r.jsx)(n.code,{children:"/models"})," folder."]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Jan automatically generates a corresponding ",(0,r.jsx)(n.code,{children:"model.json"})," file based on the binary filename."]}),"\n",(0,r.jsxs)(n.li,{children:["Jan automatically organizes it into its own ",(0,r.jsx)(n.code,{children:"/models/model-id"})," folder."]}),"\n",(0,r.jsxs)(n.li,{children:["Jan automatically populates the ",(0,r.jsx)(n.code,{children:"model.json"})," properties, which you can subsequently modify."]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},28453:(e,n,o)=>{o.d(n,{R:()=>i,x:()=>s});var r=o(96540);const l={},a=r.createContext(l);function i(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:i(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);