"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[259],{30749:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>r,default:()=>h,frontMatter:()=>s,metadata:()=>l,toc:()=>d});var o=t(74848),i=t(28453);const s={title:"Remote Server Integration",sidebar_position:1,slug:"/guides/engines/remote-server",description:"A step-by-step guide on how to set up Jan to connect with any remote or local API server.",keywords:["Jan","Customizable Intelligence","LLM","local AI","privacy focus","free and open source","private and offline","conversational AI","no-subscription fee","large language models","import-models-manually","remote server","OAI compatible"]},r=void 0,l={id:"guides/remote-providers/remote-server-integration",title:"Remote Server Integration",description:"A step-by-step guide on how to set up Jan to connect with any remote or local API server.",source:"@site/docs/guides/remote-providers/remote-server-integration.mdx",sourceDirName:"guides/remote-providers",slug:"/guides/engines/remote-server",permalink:"/guides/engines/remote-server",draft:!1,unlisted:!1,editUrl:"https://github.com/janhq/docs/tree/main/docs/guides/remote-providers/remote-server-integration.mdx",tags:[],version:"current",lastUpdatedBy:"Henry",lastUpdatedAt:1711669448,formattedLastUpdatedAt:"Mar 28, 2024",sidebarPosition:1,frontMatter:{title:"Remote Server Integration",sidebar_position:1,slug:"/guides/engines/remote-server",description:"A step-by-step guide on how to set up Jan to connect with any remote or local API server.",keywords:["Jan","Customizable Intelligence","LLM","local AI","privacy focus","free and open source","private and offline","conversational AI","no-subscription fee","large language models","import-models-manually","remote server","OAI compatible"]},sidebar:"guidesSidebar",previous:{title:"Azure OpenAI",permalink:"/guides/engines/openai"},next:{title:"What are Jan Extensions?",permalink:"/extensions"}},a={},d=[{value:"OpenAI Platform Configuration",id:"openai-platform-configuration",level:2},{value:"1. Create a Model JSON",id:"1-create-a-model-json",level:3},{value:"<code>model.json</code>",id:"modeljson",level:3},{value:"Settings",id:"settings",level:4},{value:"Parameters",id:"parameters",level:4},{value:"2. Configure OpenAI API Keys",id:"2-configure-openai-api-keys",level:3},{value:"3. Start the Model",id:"3-start-the-model",level:3},{value:"Engines with OAI Compatible Configuration",id:"engines-with-oai-compatible-configuration",level:2},{value:"1. Configure a Client Connection",id:"1-configure-a-client-connection",level:3},{value:"2. Create a Model JSON",id:"2-create-a-model-json",level:3},{value:"3. Start the Model",id:"3-start-the-model-1",level:3}];function c(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",h4:"h4",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"This guide will show you how to configure Jan as a client and point it to any remote & local (self-hosted) API server."}),"\n",(0,o.jsx)(n.h2,{id:"openai-platform-configuration",children:"OpenAI Platform Configuration"}),"\n",(0,o.jsx)(n.h3,{id:"1-create-a-model-json",children:"1. Create a Model JSON"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["In ",(0,o.jsx)(n.code,{children:"~/jan/models"}),", create a folder named ",(0,o.jsx)(n.code,{children:"gpt-3.5-turbo-16k"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["In this folder, add a ",(0,o.jsx)(n.code,{children:"model.json"})," file with Filename as ",(0,o.jsx)(n.code,{children:"model.json"}),", ",(0,o.jsx)(n.code,{children:"id"})," matching folder name, ",(0,o.jsx)(n.code,{children:"Format"})," as ",(0,o.jsx)(n.code,{children:"api"}),", ",(0,o.jsx)(n.code,{children:"Engine"})," as ",(0,o.jsx)(n.code,{children:"openai"}),", and ",(0,o.jsx)(n.code,{children:"State"})," as ",(0,o.jsx)(n.code,{children:"ready"}),"."]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",metastring:'title="~/jan/models/gpt-3.5-turbo-16k/model.json"',children:'{\n  "sources": [\n    {\n      "filename": "openai",\n      "url": "https://openai.com"\n    }\n  ],\n  "id": "gpt-3.5-turbo-16k",\n  "object": "model",\n  "name": "OpenAI GPT 3.5 Turbo 16k",\n  "version": "1.0",\n  "description": "OpenAI GPT 3.5 Turbo 16k model is extremely good",\n  "format": "api",\n  "settings": {},\n  "parameters": {},\n  "metadata": {\n    "author": "OpenAI",\n    "tags": ["General", "Big Context Length"]\n  },\n  "engine": "openai"\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"modeljson",children:(0,o.jsx)(n.code,{children:"model.json"})}),"\n",(0,o.jsxs)(n.p,{children:["The ",(0,o.jsx)(n.code,{children:"model.json"})," file is used to set up your local models."]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["If you've set up your model's configuration in ",(0,o.jsx)(n.code,{children:"nitro.json"}),", please note that ",(0,o.jsx)(n.code,{children:"model.json"})," can overwrite the settings."]}),"\n",(0,o.jsxs)(n.li,{children:["When using OpenAI models like GPT-3.5 and GPT-4, you can use the default settings in ",(0,o.jsx)(n.code,{children:"model.json"})," file."]}),"\n"]})}),"\n",(0,o.jsx)(n.p,{children:"There are two important fields in model.json that you need to setup:"}),"\n",(0,o.jsx)(n.h4,{id:"settings",children:"Settings"}),"\n",(0,o.jsx)(n.p,{children:"This is the field where to set your engine configurations, there are two imporant field that you need to define for your local models:"}),"\n",(0,o.jsxs)(n.table,{children:[(0,o.jsx)(n.thead,{children:(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.th,{children:"Term"}),(0,o.jsx)(n.th,{children:"Description"})]})}),(0,o.jsxs)(n.tbody,{children:[(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"ctx_len"})}),(0,o.jsx)(n.td,{children:"Defined based on the model's context size."})]}),(0,o.jsxs)(n.tr,{children:[(0,o.jsx)(n.td,{children:(0,o.jsx)(n.code,{children:"prompt_template"})}),(0,o.jsx)(n.td,{children:"Defined based on the model's trained template (e.g., ChatML, Alpaca)."})]})]})]}),"\n",(0,o.jsxs)(n.p,{children:["To set up the ",(0,o.jsx)(n.code,{children:"prompt_template"})," based on your model, follow the steps below: 1. Visit ",(0,o.jsx)(n.a,{href:"https://huggingface.co/",children:"Hugging Face"}),", an open-source machine learning platform. 2. Find the current model that you're using (e.g., ",(0,o.jsx)(n.a,{href:"https://huggingface.co/google/gemma-7b-it",children:"Gemma 7b it"}),"). 3. Review the text and identify the template."]}),"\n",(0,o.jsx)(n.h4,{id:"parameters",children:"Parameters"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"parameters"})," is the adjustable settings that affect how your model operates or processes the data.\nThe fields in ",(0,o.jsx)(n.code,{children:"parameters"})," are typically general and can be the same across models. An example is provided below:"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",children:'"parameters":{\n  "temperature": 0.7,\n  "top_p": 0.95,\n  "stream": true,\n  "max_tokens": 4096,\n  "frequency_penalty": 0,\n  "presence_penalty": 0\n}\n'})}),"\n",(0,o.jsx)(n.admonition,{type:"tip",children:(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["You can find the list of available models in the ",(0,o.jsx)(n.a,{href:"https://platform.openai.com/docs/models/overview",children:"OpenAI Platform"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["The ",(0,o.jsx)(n.code,{children:"id"})," property needs to match the model name in the list.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["For example, if you want to use the ",(0,o.jsx)(n.a,{href:"https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo",children:"GPT-4 Turbo"}),", you must set the ",(0,o.jsx)(n.code,{children:"id"})," property to ",(0,o.jsx)(n.code,{children:"gpt-4-1106-preview"}),"."]}),"\n"]}),"\n"]}),"\n"]})}),"\n",(0,o.jsx)(n.h3,{id:"2-configure-openai-api-keys",children:"2. Configure OpenAI API Keys"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Find your API keys in the ",(0,o.jsx)(n.a,{href:"https://platform.openai.com/api-keys",children:"OpenAI Platform"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Set the OpenAI API keys in ",(0,o.jsx)(n.code,{children:"~/jan/engines/openai.json"})," file."]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",metastring:'title="~/jan/engines/openai.json"',children:'{\n  "full_url": "https://api.openai.com/v1/chat/completions",\n  "api_key": "sk-<your key here>"\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"3-start-the-model",children:"3. Start the Model"}),"\n",(0,o.jsx)(n.p,{children:"Restart Jan and navigate to the Hub. Then, select your configured model and start the model."}),"\n",(0,o.jsx)(n.h2,{id:"engines-with-oai-compatible-configuration",children:"Engines with OAI Compatible Configuration"}),"\n",(0,o.jsxs)(n.p,{children:["This section will show you how to configure a client connection to a remote/local server using Jan's API server running model ",(0,o.jsx)(n.code,{children:"mistral-ins-7b-q4"})," as an example."]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsx)(n.p,{children:"Currently, you can only connect to one OpenAI-compatible endpoint at a time."})}),"\n",(0,o.jsx)(n.h3,{id:"1-configure-a-client-connection",children:"1. Configure a Client Connection"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Navigate to the ",(0,o.jsx)(n.code,{children:"~/jan/engines"})," folder."]}),"\n",(0,o.jsxs)(n.li,{children:["Modify the ",(0,o.jsx)(n.code,{children:"openai.json file"}),"."]}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{type:"note",children:(0,o.jsxs)(n.p,{children:["Please note that currently, the code that supports any OpenAI-compatible endpoint only reads ",(0,o.jsx)(n.code,{children:"engine/openai.json"})," file. Thus, it will not search any other files in this directory."]})}),"\n",(0,o.jsxs)(n.ol,{start:"3",children:["\n",(0,o.jsxs)(n.li,{children:["Configure ",(0,o.jsx)(n.code,{children:"full_url"})," properties with the endpoint server that you want to connect. For example, if you're going to communicate to Jan's API server, you can configure it as follows:"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",metastring:'title="~/jan/engines/openai.json"',children:'{\n  // "full_url": "https://<server-ip-address>:<port>/v1/chat/completions"\n  "full_url": "https://<server-ip-address>:1337/v1/chat/completions"\n  // Skip api_key if your local server does not require authentication\n  // "api_key": "sk-<your key here>"\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"2-create-a-model-json",children:"2. Create a Model JSON"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["In ",(0,o.jsx)(n.code,{children:"~/jan/models"}),", create a folder named ",(0,o.jsx)(n.code,{children:"mistral-ins-7b-q4"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["In this folder, add a ",(0,o.jsx)(n.code,{children:"model.json"})," file with Filename as ",(0,o.jsx)(n.code,{children:"model.json"}),", ensure the following configurations:"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"id"})," matching folder name."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"Format"})," set to ",(0,o.jsx)(n.code,{children:"api"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"Engine"})," set to ",(0,o.jsx)(n.code,{children:"openai"})]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.code,{children:"State"})," set to ",(0,o.jsx)(n.code,{children:"ready"}),"."]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-json",metastring:'title="~/jan/models/mistral-ins-7b-q4/model.json"',children:'{\n  "sources": [\n    {\n      "filename": "janai",\n      "url": "https://jan.ai"\n    }\n  ],\n  "id": "mistral-ins-7b-q4",\n  "object": "model",\n  "name": "Mistral Instruct 7B Q4 on Jan API Server",\n  "version": "1.0",\n  "description": "Jan integration with remote Jan API server",\n  "format": "api",\n  "settings": {},\n  "parameters": {},\n  "metadata": {\n    "author": "MistralAI, The Bloke",\n    "tags": ["remote", "awesome"]\n  },\n  "engine": "openai"\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"3-start-the-model-1",children:"3. Start the Model"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["Restart Jan and navigate to the ",(0,o.jsx)(n.strong,{children:"Hub"}),"."]}),"\n",(0,o.jsxs)(n.li,{children:["Locate your model and click the ",(0,o.jsx)(n.strong,{children:"Use"})," button."]}),"\n"]}),"\n",(0,o.jsx)(n.admonition,{title:"Assistance and Support",type:"info",children:(0,o.jsxs)(n.p,{children:["If you have questions or want more preconfigured GGUF models, please join our ",(0,o.jsx)(n.a,{href:"https://discord.gg/Dt7MxDyNNZ",children:"Discord community"})," for support, updates, and discussions."]})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var o=t(96540);const i={},s=o.createContext(i);function r(e){const n=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),o.createElement(s.Provider,{value:n},e.children)}}}]);