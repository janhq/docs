---
title: OpenAI API
description: A step-by-step guide on how to integrate Jan with Azure OpenAI.
keywords:
  [
    Jan,
    Customizable Intelligence, LLM,
    local AI,
    privacy focus,
    free and open source,
    private and offline,
    conversational AI,
    no-subscription fee,
    large language models,
    integration,
    Azure OpenAI Service,
  ]
---

import { Callout, Steps } from 'nextra/components'



# OpenAI API

## How to Integrate OpenAI API with Jan

<Steps>
### Step 1: Create a Model JSON

1. In `~/jan/models`, create a folder named `gpt-3.5-turbo-16k`.

2. In this folder, add a `model.json` file with Filename as `model.json`, `id` matching folder name, `Format` as `api`, `Engine` as `openai`, and `State` as `ready`.

```json title="~/jan/models/gpt-3.5-turbo-16k/model.json"
{
  "sources": [
    {
      "filename": "openai",
      "url": "https://openai.com"
    }
  ],
  "id": "gpt-3.5-turbo-16k",
  "object": "model",
  "name": "OpenAI GPT 3.5 Turbo 16k",
  "version": "1.0",
  "description": "OpenAI GPT 3.5 Turbo 16k model is extremely good",
  "format": "api",
  "settings": {},
  "parameters": {},
  "metadata": {
    "author": "OpenAI",
    "tags": ["General", "Big Context Length"]
  },
  "engine": "openai"
}
```

### `model.json`

The `model.json` file is used to set up your local models.
:::note

- If you've set up your model's configuration in `nitro.json`, please note that `model.json` can overwrite the settings.
- When using OpenAI models like GPT-3.5 and GPT-4, you can use the default settings in `model.json` file.
  :::

There are two important fields in model.json that you need to setup:

#### Settings

This is the field where to set your engine configurations, there are two imporant field that you need to define for your local models:

| Term              | Description                                                           |
| ----------------- | --------------------------------------------------------------------- |
| `ctx_len`         | Defined based on the model's context size.                            |
| `prompt_template` | Defined based on the model's trained template (e.g., ChatML, Alpaca). |

To set up the `prompt_template` based on your model, follow the steps below: 1. Visit [Hugging Face](https://huggingface.co/), an open-source machine learning platform. 2. Find the current model that you're using (e.g., [Gemma 7b it](https://huggingface.co/google/gemma-7b-it)). 3. Review the text and identify the template.

#### Parameters

`parameters` is the adjustable settings that affect how your model operates or processes the data.
The fields in `parameters` are typically general and can be the same across models. An example is provided below:

```json
"parameters":{
  "temperature": 0.7,
  "top_p": 0.95,
  "stream": true,
  "max_tokens": 4096,
  "frequency_penalty": 0,
  "presence_penalty": 0
}
```

:::tip

- You can find the list of available models in the [OpenAI Platform](https://platform.openai.com/docs/models/overview).
- The `id` property needs to match the model name in the list.
  - For example, if you want to use the [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo), you must set the `id` property to `gpt-4-1106-preview`.

:::

### Step 2: Configure OpenAI API Keys

1. Find your API keys in the [OpenAI Platform](https://platform.openai.com/api-keys).
2. Set the OpenAI API keys in `~/jan/engines/openai.json` file.

```json title="~/jan/engines/openai.json"
{
  "full_url": "https://api.openai.com/v1/chat/completions",
  "api_key": "sk-<your key here>"
}
```

### Step 3: Start the Model

Restart Jan and navigate to the Hub. Then, select your configured model and start the model.

## How to Integrate Azure OpenAI API with Jan

The [Azure OpenAI Service](https://learn.microsoft.com/en-us/azure/ai-services/openai/overview?source=docs) offers robust APIs, making it simple for you to incorporate OpenAI's language models into your applications. You can integrate Azure OpenAI with Jan by following the steps below:
</Steps>
<Steps>

### Step 1: Configure Azure OpenAI Service API Key

1. Set up and deploy the Azure OpenAI Service.
2. Once you've set up and deployed Azure OpenAI Service, you can find the endpoint and API key in [Azure OpenAI Studio](https://oai.azure.com/) under `Chat` > `View code`.

3. Set up the endpoint and API key for Azure OpenAI Service in the `~/jan/engines/openai.json` file.

```json title="~/jan/engines/openai.json"
{
  // https://hieujan.openai.azure.com/openai/deployments/gpt-35-hieu-jan/chat/completions?api-version=2023-07-01-preview
  "full_url": "https://<your-resource-name>.openai.azure.com/openai/deployments/<your-deployment-name>/chat/completions?api-version=<api-version>",
  "api_key": "<your-api-key>"
}
```

### Step 2: Model Configuration

1. Go to the `~/jan/models` directory.
2. Make a new folder called `(your-deployment-name)`, for example `gpt-35-hieu-jan`.
3. Create a `model.json` file inside the folder with the specified configurations:

- Match the `id` property with both the folder name and your deployment name.
- Set the `format` property as `api`.
- Choose `openai` for the `engine` property.
- Set the `state` property as `ready`.

```json ~/jan/models/gpt-35-hieu-jan/model.json
{
  "sources": [
    {
      "filename": "azure_openai",
      "url": "https://hieujan.openai.azure.com"
    }
  ],
  "id": "gpt-35-hieu-jan",
  "object": "model",
  "name": "Azure OpenAI GPT 3.5",
  "version": "1.0",
  "description": "Azure Open AI GPT 3.5 model is extremely good",
  "format": "api",
  "settings": {},
  "parameters": {},
  "metadata": {
    "author": "OpenAI",
    "tags": ["General", "Big Context Length"]
  },
  "engine": "openai"
}
```

<Callout type='info'>
  For more details regarding the `model.json` settings and parameters fields, please see [here](/docs/engines-remote/remote-server-integration#modeljson).
</Callout>

### Step 3: Start the Model

1. Restart Jan and go to the Hub.
2. Find your model in Jan application and click on the Use button.

</Steps>