---
title: Custom Overview
description: Jan is an open-source, self-hosted alternative to OpenAI's platform - build and run AI on your own desktop or server.
keywords:
  [
    Jan,
    Jan AI,
    ChatGPT alternative,
    OpenAI platform alternative,
    local API,
    local AI,
    private AI,
    conversational AI,
    no-subscription fee,
    large language model,
    LLM,
  ]
---

import { Callout } from 'nextra/components'

# Custom Overview

Jan is an open-source, self-hosted alternative to OpenAI's platform. It allows you to build, run, and fine-tune (coming soon) on your own desktop or server. Featuring a local API server that mirrors OpenAI's, Jan operates directly from your device (localhost:1337), enabling immediate access to AI capabilities with full control over your data.

To use Jan, please refer to the quick start guide [here](https://jan.ai/docs/quickstart).

## Jan's Basics

### Models
Jan lets you run and manage different AI models on your own device. Choose between running AI models locally for privacy, like `Llama` or `Mistral`, or connect to remote APIs, like `ChatGPT` or `Claude`. This feature supports customizing and optimizing AI to meet the needs of your projects directly, with a focus on maintaining speed and privacy. You can download and import models directly through Jan Hub, making it easy to expand your AI capabilities.

### Threads
Jan offers a simple and secure way to manage your AI interaction threads directly on your device. Every interaction with AI through Jan is saved as a thread, allowing you to keep a record of your exchanges. Jan provides tools that let you efficiently sort, remove, or review these threads. This ensures that your AI interaction history is easily accessible, while also being kept private and well-managed.

### Local API Server
Jan’s local API server acts as a `drop-in replacement for OpenAI's API`, allowing you to run AI models on your own server. This setup offers AI functionality on your local machine, giving you complete control over your data and privacy.

### Inferences
Jan supports multiple inferences, including `Llama.cpp`, `TensorRT-LLM`, `Mistral API`, `OpenAI API`, `Groq API`, `LM Studio`, `Ollama`, and other `OAI-compatible servers`.

### Extensions
Jan’s architecture supports a variety of extensions, enabling enhanced functionality and inference options. Each extension is designed to meet specific needs, ensuring that Jan can be tailored to the unique demands of your projects.

### Integrations
Jan integrates with an array of tools and platforms to streamline your workflow. This includes seamless connections with services like `Discord`, `Open Interpreter`, `Raycast`, and `OpenRouter`. 

### Assistants (Coming soon)
Jan will soon enable the creation of AI assistants for task automation and response generation. These assistants will be customizable, allowing for a range of interactions from simple commands to complex conversations.

## Quick Guides

- **[Models](https://jan.ai/docs/models):** Manage and deploy AI models effectively.
- **[Threads](https://jan.ai/docs/threads):** Handle multiple operations and tasks with ease.
- **[Local Server](https://jan.ai/docs/local-api):** Utilize Jan's OpenAI-Equivalent API for your applications.
- **[Advanced Settings](https://jan.ai/docs/advanced):** Navigate through Jan's advanced settings for optimal customization.
- **[Extensions](https://jan.ai/docs/extensions):** Expand Jan's capabilities with multi-inferences and specific settings for each extension.
- **[Integration](https://jan.ai/docs/integrations):** Integrate Jan with key tools and platforms to enhance your development environment.
