<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">One post tagged with &quot;TensorRT-LLM&quot; | Jan | Rethink the Computer</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:image" content="https://jan.ai/img/og-image.png"><meta data-rh="true" property="og:url" content="https://jan.ai/blog/tags/tensor-rt-llm/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="description" content="Jan turns your computer into an AI machine by running LLMs locally on your computer. It&#x27;s a privacy-focus, local-first, open-source solution."><meta data-rh="true" name="keywords" content="Jan, Rethink the Computer, LLM, local AI, privacy focus, free and open source, private and offline, conversational AI, no-subscription fee, large language models"><meta data-rh="true" property="og:description" content="Jan turns your computer into an AI machine by running LLMs locally on your computer. It&#x27;s a privacy-focus, local-first, open-source solution."><meta data-rh="true" property="og:image" content="https://jan.ai/img/og-image.png"><meta data-rh="true" property="og:type" content="website"><meta data-rh="true" property="twitter:card" content="summary_large_image"><meta data-rh="true" property="twitter:site" content="@janframework"><meta data-rh="true" property="twitter:title" content="Jan | Rethink the Computer"><meta data-rh="true" property="twitter:description" content="Jan turns your computer into an AI machine by running LLMs locally on your computer. It&#x27;s a privacy-focus, local-first, open-source solution."><meta data-rh="true" property="twitter:image" content="https://jan.ai/img/og-image.png"><meta data-rh="true" property="og:title" content="One post tagged with &quot;TensorRT-LLM&quot; | Jan | Rethink the Computer"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="robots" content="noindex, nofollow"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://jan.ai/blog/tags/tensor-rt-llm/"><link data-rh="true" rel="alternate" href="https://jan.ai/blog/tags/tensor-rt-llm/" hreflang="en"><link data-rh="true" rel="alternate" href="https://jan.ai/blog/tags/tensor-rt-llm/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://Y8QU1SIVLP-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Jan | Rethink the Computer RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Jan | Rethink the Computer Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n,g){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var m=t.getElementsByTagName(a)[0],r=t.createElement(a);r.async=!0,r.src="https://www.googletagmanager.com/gtm.js?id=G-YK53MX8M8M",m.parentNode.insertBefore(r,m)}(window,document,"script","dataLayer")</script>



<link rel="search" type="application/opensearchdescription+xml" title="Jan | Rethink the Computer" href="/opensearch.xml">



<link rel="preconnect" href="XXX">
<script>!function(t,e){var o,i,n,p;e.__SV||(window.posthog=e,e._i=[],e.init=function(r,s,a){function c(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(n=t.createElement("script")).type="text/javascript",n.async=!0,n.src=s.api_host+"/static/array.js",(p=t.getElementsByTagName("script")[0]).parentNode.insertBefore(n,p);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="capture identify alias people.set people.set_once set_config register register_once unregister opt_out_capturing has_opted_out_capturing opt_in_capturing reset".split(" "),i=0;i<o.length;i++)c(u,o[i]);e._i.push([r,s,a])},e.__SV=1)}(document,window.posthog||[]),posthog.init("XXX",{api_host:"XXX",id:"default"})</script><link rel="stylesheet" href="/assets/css/styles.7c2d1dc4.css">
<script src="/assets/js/runtime~main.57ec3ea1.js" defer="defer"></script>
<script src="/assets/js/main.0d696aee.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-YK53MX8M8M" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Jan Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Jan Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Jan</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about/">What is Jan?</a></li><li><a class="dropdown__link" href="/team/">Who we are</a></li><li><a class="dropdown__link" href="/wall-of-love/">Wall of love</a></li></ul></div><a class="navbar__item navbar__link" href="/download/">Download</a><a class="navbar__item navbar__link" href="/api-reference/"></a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/docs/">Docs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/guides/">Guides</a></li><li><a class="dropdown__link" href="/developer/">Developer</a></li><li><a class="dropdown__link" href="/api-reference/">API Reference</a></li><li><a class="dropdown__link" href="/changelog/">Changelog</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog/">Blog</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_l3_l"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">All Posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/postmortems/january-10-2024-bitdefender-false-positive-flag/">Post Mortem: Bitdefender False Positive Flag</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="https://schema.org/Blog"><div class="theme-admonition theme-admonition-caution admonition_xJq3 alert alert--warning theme-unlisted-banner"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Unlisted page</div><div class="admonitionContent_BuS1">This page is unlisted. Search engines will not index it, and only users having a direct link can access it.</div></div><header class="margin-bottom--xl"><h1>One post tagged with &quot;TensorRT-LLM&quot;</h1><a href="/blog/tags/">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="Jan has added support for the TensorRT-LLM Inference Engine, as an alternative to llama.cpp. We provide a performance benchmark that shows the head-to-head comparison of the two Inference Engine and model formats, with TensorRT-LLM providing better performance but consumes significantly more VRAM and RAM."><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/2024/03/19/TensorRT-LLM/">Benchmarking TensorRT-LLM vs. llama.cpp</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2024-03-19T00:00:00.000Z" itemprop="datePublished">March 19, 2024</time> · <!-- -->5 min read</div></header><div class="markdown" itemprop="articleBody"><p>Jan has added support <a href="https://github.com/NVIDIA/TensorRT-LLM" target="_blank" rel="noopener noreferrer">TensorRT-LLM</a> as an alternative to the default <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a> inference engine. TensorRT-LLM allows Nvidia GPU owners to run blazing fast LLM inference as a hardware-optimized LLM inference engine that compiles models to <a href="https://blogs.nvidia.com/blog/tensorrt-llm-windows-stable-diffusion-rtx/" target="_blank" rel="noopener noreferrer">run extremely fast on Nvidia GPUs</a>.</p>
<p>You can follow our <a href="/guides/providers/tensorrt-llm/">TensorRT-LLM Guide</a> to try it out today. We&#x27;ve also added a few TensorRT-LLM models to Jan&#x27;s Model Hub for download:</p>
<ul>
<li>Mistral 7b</li>
<li>TinyLlama-1.1b</li>
<li>TinyJensen-1.1b 😂</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>TensorRT-LLM support is available in <a href="https://github.com/janhq/jan/releases/tag/v0.4.9" target="_blank" rel="noopener noreferrer">v0.4.9</a>, but should be considered an experimental feature.</p><p>Please report bugs on <a href="https://github.com/janhq/jan" target="_blank" rel="noopener noreferrer">Github</a> or on our Discord&#x27;s <a href="https://discord.com/channels/1107178041848909847/1201832734704795688" target="_blank" rel="noopener noreferrer">#tensorrt-llm</a> channel.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance-benchmarks">Performance Benchmarks<a href="#performance-benchmarks" class="hash-link" aria-label="Direct link to Performance Benchmarks" title="Direct link to Performance Benchmarks">​</a></h2>
<p>We were really curious to see how TensorRT-LLM would perform vs. llama.cpp on consumer-grade GPUs. TensorRT-LLM has previously been shown by Nvidia to reach performance of up to <a href="https://nvidia.github.io/TensorRT-LLM/blogs/H100vsA100.html" target="_blank" rel="noopener noreferrer">10,000 tokens/s</a> on datacenter-grade GPUs. As most of Jan&#x27;s users are proud card carrying members of the <a href="https://www.semianalysis.com/p/google-gemini-eats-the-world-gemini#the-gpu-poor" target="_blank" rel="noopener noreferrer">GPU Poor</a>, we wanted to see how the two inference engine performed on the same hardware.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>An interesting aside: Jan actually started out in June 2023 building on <a href="https://github.com/NVIDIA/FasterTransformer" target="_blank" rel="noopener noreferrer">FastTransformer</a>, the precursor library to TensorRT-LLM. TensorRT-LLM was released in September 2023, making it a very young library. We&#x27;re excited to see it&#x27;s roadmap develop!</p></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="test-setup">Test Setup<a href="#test-setup" class="hash-link" aria-label="Direct link to Test Setup" title="Direct link to Test Setup">​</a></h3>
<p>We picked 3 hardware platforms to run the test on, based on Jan&#x27;s userbase&#x27;s self-reported common hardware platforms.</p>
<table><thead><tr><th>NVIDIA GPU</th><th>VRAM Used (GB)</th><th>CUDA Cores</th><th>Tensor Cores</th><th>Memory Bus Width (bit)</th><th>Memory Bandwidth (GB/s)</th></tr></thead><tbody><tr><td>RTX 4090 Desktop (Ada)</td><td>24</td><td>16,384</td><td>512</td><td>384</td><td>~1000</td></tr><tr><td>RTX 3090 Desktop (Ampere)</td><td>24</td><td>10,496</td><td>328</td><td>384</td><td>935.8</td></tr><tr><td>RTX 4060 Laptop (Ada)</td><td>8</td><td>3,072</td><td>96</td><td>128</td><td>272</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Low-spec Machines?</div><div class="admonitionContent_BuS1"><p>We didn&#x27;t bother including low-spec machines: TensorRT-LLM is meant for performance, and simply doesn&#x27;t work on lower grade Nvidia GPUs, or computers without GPUs.</p><p>TensorRT-LLM provides blazing fast performance at the cost of <a href="https://nvidia.github.io/TensorRT-LLM/memory.html" target="_blank" rel="noopener noreferrer">memory usage</a>. This means that the performance improvements only show up in higher-range GPUs with larger VRAMs.</p><p>We&#x27;ve found that <a href="https://github.com/ggerganov/llama.cpp" target="_blank" rel="noopener noreferrer">llama.cpp</a> does an incredible job of democratizing inference to the <a href="https://www.semianalysis.com/p/google-gemini-eats-the-world-gemini#the-gpu-poor" target="_blank" rel="noopener noreferrer">GPU Poor</a> with CPU-only or lower-range GPUs. Huge shout outs to the <a href="https://github.com/ggerganov/llama.cpp/graphs/contributors" target="_blank" rel="noopener noreferrer">llama.cpp maintainers</a> and the <a href="https://ggml.ai/" target="_blank" rel="noopener noreferrer">ggml.ai</a> team.</p></div></div>
<p>We chose the popular Mistral 7b model to run on both GGUF and TensorRT-LLM, picking comparable quantizations.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="llamacpp-setup">llama.cpp Setup<a href="#llamacpp-setup" class="hash-link" aria-label="Direct link to llama.cpp Setup" title="Direct link to llama.cpp Setup">​</a></h4>
<ul class="contains-task-list containsTaskList_mC6p">
<li>For llama.cpp, we used <code>Mistral-7b-q4_k_m</code></li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Fill in <code>ngl</code> params, GPU offload etc</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="tensorrt-llm-setup">TensorRT-LLM Setup<a href="#tensorrt-llm-setup" class="hash-link" aria-label="Direct link to TensorRT-LLM Setup" title="Direct link to TensorRT-LLM Setup">​</a></h4>
<ul>
<li>For TensorRT-LLM, we used <code>Mistral-7b-int4 AWQ</code></li>
<li>We ran TensorRT-LLM with <code>free_gpu_memory_fraction</code> to test it with the lowest VRAM consumption (performance may be affected)</li>
<li>Note: We picked AWQ for TensorRT-LLM as a handicap as AWQ supposedly sacrifices performance for quality</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="experiment-setup">Experiment Setup<a href="#experiment-setup" class="hash-link" aria-label="Direct link to Experiment Setup" title="Direct link to Experiment Setup">​</a></h4>
<p>We ran the experiment using a standardized inference request in a sandboxed environment on the same machine:</p>
<ul>
<li>We ran tests 5 times for each inference engine, on a baremetal PC with no other applications open</li>
<li>Each inference request was of <code>batch_size</code> 1 and <code>input_len</code> 2048, <code>output_len</code> 512 as a realistic test case</li>
<li>CPU and Memory usage were obtained from.... Windows Task Manager 😱</li>
<li>GPU usage was obtained from <code>nvtop</code>, <code>htop</code>, and <code>nvidia-smi</code></li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a href="#results" class="hash-link" aria-label="Direct link to Results" title="Direct link to Results">​</a></h2>
<p>Our biggest takeaway: TensorRT-LLM is faster than llama.cpp on 4090s and 3090s with larger VRAMs. However, on smaller GPUs (e.g. Laptop 4060 GPUs),</p>
<table><thead><tr><th></th><th>4090 Desktop</th><th>3090 Desktop</th><th>4060 Laptop</th></tr></thead><tbody><tr><td>TensorRT-LLM</td><td>✅ 159t/s</td><td>✅ 140.27t/s</td><td>❌ 19t/s</td></tr><tr><td>llama.cpp</td><td>101.3t/s</td><td>90t/s</td><td>22t/s</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="rtx-4090-desktop">RTX-4090 Desktop<a href="#rtx-4090-desktop" class="hash-link" aria-label="Direct link to RTX-4090 Desktop" title="Direct link to RTX-4090 Desktop">​</a></h3>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Hardware Details</div><div class="admonitionContent_BuS1"><ul>
<li>CPU: Intel 13th series</li>
<li>GPU: NVIDIA GPU 4090 (Ampere - sm 86)</li>
<li>RAM: 32GB</li>
<li>OS: Windows 11 Pro on Proxmox</li>
</ul></div></div>
<p>Nvidia&#x27;s RTX-4090 is their top-of-the-line consumer GPU, and retails for <a href="https://www.amazon.com/rtx-4090/s?k=rtx+4090" target="_blank" rel="noopener noreferrer">approximately $2,000</a>.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="mistral-7b-int4">Mistral-7b int4<a href="#mistral-7b-int4" class="hash-link" aria-label="Direct link to Mistral-7b int4" title="Direct link to Mistral-7b int4">​</a></h4>
<table><thead><tr><th>Metrics</th><th>GGUF (using GPU)</th><th>TensorRT-LLM</th><th>Difference</th></tr></thead><tbody><tr><td>Throughput (token/s)</td><td>101.3</td><td>159</td><td>✅ 57% faster</td></tr><tr><td>VRAM Used (GB)</td><td>5.5</td><td>6.3</td><td>🤔 14% more</td></tr><tr><td>RAM Used (GB)</td><td>0.54</td><td>0.42</td><td>🤯 20% less</td></tr><tr><td>Disk Size (GB)</td><td>4.07</td><td>3.66</td><td>🤯 10% smaller</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="rtx-3090-desktop">RTX-3090 Desktop<a href="#rtx-3090-desktop" class="hash-link" aria-label="Direct link to RTX-3090 Desktop" title="Direct link to RTX-3090 Desktop">​</a></h3>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Hardware Details</div><div class="admonitionContent_BuS1"><ul>
<li>CPU: Intel 13th series</li>
<li>GPU: NVIDIA GPU 3090 (Ampere - sm 86)</li>
<li>RAM: 64GB</li>
<li>OS: Windows</li>
</ul></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="mistral-7b-int4-1">Mistral-7b int4<a href="#mistral-7b-int4-1" class="hash-link" aria-label="Direct link to Mistral-7b int4" title="Direct link to Mistral-7b int4">​</a></h4>
<table><thead><tr><th>Metrics</th><th>GGUF (using GPU)</th><th>TensorRT-LLM</th><th>Difference</th></tr></thead><tbody><tr><td>Throughput (token/s)</td><td>90</td><td>✅ 140.27</td><td>✅ 55% faster</td></tr><tr><td>VRAM Used (GB)</td><td>6.0</td><td>6.8</td><td>🤔 13% more</td></tr><tr><td>RAM Used (GB)</td><td>0.54</td><td>0.42</td><td>🤯 22% less</td></tr><tr><td>Disk Size (GB)</td><td>4.07</td><td>3.66</td><td>🤯 10% less</td></tr></tbody></table>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="rtx-4060-laptop">RTX-4060 Laptop<a href="#rtx-4060-laptop" class="hash-link" aria-label="Direct link to RTX-4060 Laptop" title="Direct link to RTX-4060 Laptop">​</a></h3>
<ul class="contains-task-list containsTaskList_mC6p">
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Dan to re-run perf tests and fill in details</li>
</ul>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Hardware Details</div><div class="admonitionContent_BuS1"><ul>
<li>Manufacturer: Acer Nitro 16 Phenix</li>
<li>CPU: Ryzen 7000</li>
<li>RAM: 16GB</li>
<li>GPU: NVIDIA Laptop GPU 4060 (Ada)</li>
</ul></div></div>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="mistral-7b-int4-2">Mistral-7b int4<a href="#mistral-7b-int4-2" class="hash-link" aria-label="Direct link to Mistral-7b int4" title="Direct link to Mistral-7b int4">​</a></h4>
<table><thead><tr><th>Metrics</th><th>GGUF (using the GPU)</th><th>TensorRT-LLM</th><th>Difference</th></tr></thead><tbody><tr><td>Throughput (token/s)</td><td>22</td><td>❌ 19</td><td></td></tr><tr><td>VRAM Used (GB)</td><td>2.1</td><td>7.7</td><td></td></tr><tr><td>RAM Used (GB)</td><td>0.3</td><td>13.5</td><td></td></tr><tr><td>Disk Size (GB)</td><td>4.07</td><td>4.07</td><td></td></tr></tbody></table></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/nvidia/">Nvidia</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/tensor-rt-llm/">TensorRT-LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/llama-cpp/">llama.cpp</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/3090/">3090</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/4090/">4090</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/inference-engine/">inference engine</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="flex-shrink-0 relative overflow-hidden py-10"><div class="container"><div class="grid grid-cols-2 gap-8 md:grid-cols-2 lg:grid-cols-6"><div class="col-span-2"><div class="flex items-center space-x-2 mb-3"><img alt="Jan Logo" src="/img/logo.svg"><h2 class="h5">Jan</h2></div><div class="w-full lg:w-3/4 mt-2"><h6>The Soul of a New Machine</h6><p class="dark:text-gray-400 text-gray-600 mt-2">Subscribe to our newsletter on AI<!-- --> <br class="hidden lg:block">research and building Jan:</p><div class="mt-4"><form class="relative"><input type="email" class="w-full h-12 p-4 pr-14 rounded-xl border dark:border-gray-600 dark:bg-[#252525] border-[#F0F0F0]" placeholder="Enter your email" name="email"><button type="submit" class="absolute flex p-2 bg-black dark:bg-[#3B3B3C] w-8 h-8 border dark:border-gray-600 rounded-lg top-1/2 right-3 -translate-y-1/2"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M6.09026 8.41933L3.72077 7.62985C1.24061 6.80348 0 6.3903 0 5.63033C0 4.87142 1.24061 4.45718 3.72077 3.63081L12.6938 0.639442C14.4393 0.0576106 15.3121 -0.233305 15.7727 0.227312C16.2333 0.687928 15.9424 1.56068 15.3616 3.30512L12.3692 12.2792C11.5428 14.7594 11.1296 16 10.3697 16C9.61076 16 9.19652 14.7594 8.37015 12.2792L7.57962 9.9108L12.1689 5.3215C12.3609 5.1227 12.4672 4.85645 12.4648 4.58008C12.4624 4.30372 12.3515 4.03935 12.1561 3.84392C11.9607 3.64849 11.6963 3.53764 11.4199 3.53524C11.1435 3.53284 10.8773 3.63908 10.6785 3.83108L6.09026 8.41933Z" fill="white"></path></svg></button></form></div></div></div><div class="lg:text-right"><h2 class="mb-3 h6">Product</h2><ul><li><a href="/download" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Download</a></li><li><a href="/developer" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Documentation</a></li><li><a href="https://github.com/janhq/jan/releases" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Changelog</a></li></ul></div><div class="lg:text-right"><h2 class="mb-3 h6">For Developers</h2><ul><li><a href="/guides" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Guides</a></li><li><a href="/developer" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Developer</a></li><li><a href="/api-reference" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">API Reference</a></li></ul></div><div class="lg:text-right"><h2 class="mb-3 h6">Community</h2><ul><li><a href="https://github.com/janhq/jan" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Github</a></li><li><a href="https://discord.gg/FTk2MvZwJH" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Discord</a></li><li><a href="https://twitter.com/janframework" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Twitter</a></li><li><a href="https://www.linkedin.com/company/janframework/" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">LinkedIn</a></li></ul></div><div class="lg:text-right"><h2 class="mb-3 h6">Company</h2><ul><li><a href="/about" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">About</a></li><li><a href="/blog" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Blog</a></li><li><a href="https://janai.bamboohr.com/careers" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Careers</a></li><li><a href="/community#newsletter" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Newsletter</a></li></ul></div></div></div><div class="container mt-8"><div class="flex w-full justify-between items-center"><span class="dark:text-gray-300 text-gray-700">©<!-- -->2024<!-- --> Jan AI Pte Ltd.</span><div class="flex items-center gap-x-3"><a aria-label="social-0" href="https://twitter.com/janframework" target="_blank" rel="noopener"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="text-xl text-black/60 dark:text-white/60" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M928 254.3c-30.6 13.2-63.9 22.7-98.2 26.4a170.1 170.1 0 0 0 75-94 336.64 336.64 0 0 1-108.2 41.2A170.1 170.1 0 0 0 672 174c-94.5 0-170.5 76.6-170.5 170.6 0 13.2 1.6 26.4 4.2 39.1-141.5-7.4-267.7-75-351.6-178.5a169.32 169.32 0 0 0-23.2 86.1c0 59.2 30.1 111.4 76 142.1a172 172 0 0 1-77.1-21.7v2.1c0 82.9 58.6 151.6 136.7 167.4a180.6 180.6 0 0 1-44.9 5.8c-11.1 0-21.6-1.1-32.2-2.6C211 652 273.9 701.1 348.8 702.7c-58.6 45.9-132 72.9-211.7 72.9-14.3 0-27.5-.5-41.2-2.1C171.5 822 261.2 850 357.8 850 671.4 850 843 590.2 843 364.7c0-7.4 0-14.8-.5-22.2 33.2-24.3 62.3-54.4 85.5-88.2z"></path></svg></a><a aria-label="social-1" href="https://discord.com/invite/FTk2MvZwJH" target="_blank" rel="noopener"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl text-black/60 dark:text-white/60" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M14.82 4.26a10.14 10.14 0 0 0-.53 1.1 14.66 14.66 0 0 0-4.58 0 10.14 10.14 0 0 0-.53-1.1 16 16 0 0 0-4.13 1.3 17.33 17.33 0 0 0-3 11.59 16.6 16.6 0 0 0 5.07 2.59A12.89 12.89 0 0 0 8.23 18a9.65 9.65 0 0 1-1.71-.83 3.39 3.39 0 0 0 .42-.33 11.66 11.66 0 0 0 10.12 0q.21.18.42.33a10.84 10.84 0 0 1-1.71.84 12.41 12.41 0 0 0 1.08 1.78 16.44 16.44 0 0 0 5.06-2.59 17.22 17.22 0 0 0-3-11.59 16.09 16.09 0 0 0-4.09-1.35zM8.68 14.81a1.94 1.94 0 0 1-1.8-2 1.93 1.93 0 0 1 1.8-2 1.93 1.93 0 0 1 1.8 2 1.93 1.93 0 0 1-1.8 2zm6.64 0a1.94 1.94 0 0 1-1.8-2 1.93 1.93 0 0 1 1.8-2 1.92 1.92 0 0 1 1.8 2 1.92 1.92 0 0 1-1.8 2z"></path></svg></a><a aria-label="social-2" href="https://github.com/janhq/jan" target="_blank" rel="noopener"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="text-lg text-black/60 dark:text-white/60" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M511.6 76.3C264.3 76.2 64 276.4 64 523.5 64 718.9 189.3 885 363.8 946c23.5 5.9 19.9-10.8 19.9-22.2v-77.5c-135.7 15.9-141.2-73.9-150.3-88.9C215 726 171.5 718 184.5 703c30.9-15.9 62.4 4 98.9 57.9 26.4 39.1 77.9 32.5 104 26 5.7-23.5 17.9-44.5 34.7-60.8-140.6-25.2-199.2-111-199.2-213 0-49.5 16.3-95 48.3-131.7-20.4-60.5 1.9-112.3 4.9-120 58.1-5.2 118.5 41.6 123.2 45.3 33-8.9 70.7-13.6 112.9-13.6 42.4 0 80.2 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.3-43.9 2.9 7.7 24.7 58.3 5.5 118 32.4 36.8 48.9 82.7 48.9 132.3 0 102.2-59 188.1-200 212.9a127.5 127.5 0 0 1 38.1 91v112.5c.8 9 0 17.9 15 17.9 177.1-59.7 304.6-227 304.6-424.1 0-247.2-200.4-447.3-447.5-447.3z"></path></svg></a><a aria-label="social-3" href="https://www.linkedin.com/company/janframework/" target="_blank" rel="noopener"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl text-black/60 dark:text-white/60" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="4.983" cy="5.009" r="2.188"></circle><path d="M9.237 8.855v12.139h3.769v-6.003c0-1.584.298-3.118 2.262-3.118 1.937 0 1.961 1.811 1.961 3.218v5.904H21v-6.657c0-3.27-.704-5.783-4.526-5.783-1.835 0-3.065 1.007-3.568 1.96h-.051v-1.66H9.237zm-6.142 0H6.87v12.139H3.095z"></path></svg></a></div></div></div></footer></div>
</body>
</html>