<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-pending-content/blogpost/finetune-with-docs" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">How to Fine-tune Large Language Models - A Tutorial | Jan | Rethink the Computer</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:image" content="https://jan.ai/img/og-image.png"><meta data-rh="true" property="og:url" content="https://jan.ai/tutorial/how-to-fine-tune-llms/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="robots" content="index, follow"><meta data-rh="true" property="og:image" content="https://jan.ai/img/og-image.png"><meta data-rh="true" property="og:type" content="website"><meta data-rh="true" property="twitter:card" content="summary_large_image"><meta data-rh="true" property="twitter:site" content="@janframework"><meta data-rh="true" property="twitter:title" content="Jan | Rethink the Computer"><meta data-rh="true" property="twitter:description" content="Jan turns your computer into an AI machine by running LLMs locally on your computer. It&#x27;s a privacy-focus, local-first, open-source solution."><meta data-rh="true" property="twitter:image" content="https://jan.ai/img/og-image.png"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="How to Fine-tune Large Language Models - A Tutorial | Jan | Rethink the Computer"><meta data-rh="true" name="description" content="Guide on Finetuning Large Language Models with Personal Dataset"><meta data-rh="true" property="og:description" content="Guide on Finetuning Large Language Models with Personal Dataset"><meta data-rh="true" name="keywords" content="Large Language Models,Finetune LLM,Retrieval Augmented Generation,Personal Dataset,Customzied Dataset,Fine Tuning Tutorial"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://jan.ai/tutorial/how-to-fine-tune-llms/"><link data-rh="true" rel="alternate" href="https://jan.ai/tutorial/how-to-fine-tune-llms/" hreflang="en"><link data-rh="true" rel="alternate" href="https://jan.ai/tutorial/how-to-fine-tune-llms/" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://Y8QU1SIVLP-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Jan | Rethink the Computer RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Jan | Rethink the Computer Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n,g){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var m=t.getElementsByTagName(a)[0],r=t.createElement(a);r.async=!0,r.src="https://www.googletagmanager.com/gtm.js?id=G-YK53MX8M8M",m.parentNode.insertBefore(r,m)}(window,document,"script","dataLayer")</script>



<link rel="search" type="application/opensearchdescription+xml" title="Jan | Rethink the Computer" href="/opensearch.xml">



<link rel="preconnect" href="XXX">
<script>!function(t,e){var o,i,n,p;e.__SV||(window.posthog=e,e._i=[],e.init=function(r,s,a){function c(t,e){var o=e.split(".");2==o.length&&(t=t[o[0]],e=o[1]),t[e]=function(){t.push([e].concat(Array.prototype.slice.call(arguments,0)))}}(n=t.createElement("script")).type="text/javascript",n.async=!0,n.src=s.api_host+"/static/array.js",(p=t.getElementsByTagName("script")[0]).parentNode.insertBefore(n,p);var u=e;for(void 0!==a?u=e[a]=[]:a="posthog",u.people=u.people||[],u.toString=function(t){var e="posthog";return"posthog"!==a&&(e+="."+a),t||(e+=" (stub)"),e},u.people.toString=function(){return u.toString(1)+".people (stub)"},o="capture identify alias people.set people.set_once set_config register register_once unregister opt_out_capturing has_opted_out_capturing opt_in_capturing reset".split(" "),i=0;i<o.length;i++)c(u,o[i]);e._i.push([r,s,a])},e.__SV=1)}(document,window.posthog||[]),posthog.init("XXX",{api_host:"XXX",id:"default"})</script><link rel="stylesheet" href="/assets/css/styles.7c2d1dc4.css">
<script src="/assets/js/runtime~main.d9ea17fc.js" defer="defer"></script>
<script src="/assets/js/main.8ebcc9d6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=G-YK53MX8M8M" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>


<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Jan Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="Jan Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Jan</b></a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">About</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/about/">What is Jan?</a></li><li><a class="dropdown__link" href="/team/">Who we are</a></li><li><a class="dropdown__link" href="/wall-of-love/">Wall of love</a></li></ul></div><a class="navbar__item navbar__link" href="/download/">Download</a><a class="navbar__item navbar__link" href="/api-reference/"></a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a class="navbar__link" aria-haspopup="true" aria-expanded="false" role="button" href="/docs/">Docs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/guides/">Guides</a></li><li><a class="dropdown__link" href="/developer/">Developer</a></li><li><a class="dropdown__link" href="/api-reference/">API Reference</a></li><li><a class="dropdown__link" href="/changelog/">Changelog</a></li></ul></div><a class="navbar__item navbar__link" href="/blog/">Blog</a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_l3_l"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><main class="docMainContainer_TBSr docMainContainerEnhanced_lQrH"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>How to Fine-tune Large Language Models - A Tutorial</h1></header><p>Large Language Models (LLMs) are all the rage nowadays, with people using them more and more on a daily basis. As our usage increases, many use cases require the LLM to understand our data, and there are two main approaches we can use:</p>
<ol>
<li>Fine-tuning</li>
<li>Retrieval Augmented Generation (RAG)</li>
</ol>
<p>This blog will investigate the first approach to see how fine-tuning performs in understanding some technical product documentation. In detail, you will learn how to:</p>
<ol>
<li>Create a Question and Answer dataset from unstructured data</li>
<li>Fine-tune a model using the dataset</li>
<li>Run the fine-tuned model using Jan</li>
</ol>
<p>Let’s get started!</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-environment-setup">1. Environment setup<a href="#1-environment-setup" class="hash-link" aria-label="Direct link to 1. Environment setup" title="Direct link to 1. Environment setup">​</a></h2>
<p>Our first step is to install the Hugging Face libraries, which provide the backbone for running large language models (LLMs). Additionally, we&#x27;ll use LangChain as our go-to tool for efficiently handling and processing our data.</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockTitle_Ktv7">Install libraries</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Install Hugging Face libraries</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install  </span><span class="token operator">--</span><span class="token plain">upgrade \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;transformers==4.36.2&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;datasets==2.16.1&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;accelerate==0.26.1&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;evaluate==0.4.1&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;bitsandbytes==0.42.0&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Install libraries </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> generating data</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install  </span><span class="token operator">--</span><span class="token plain">upgrade \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">	</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;llama-cpp-python&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">	</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;pydantic==1.10.11&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">	</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;sentence-transformers&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">	</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;chromadb&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">	</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;langchain&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">	</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;tiktoken&quot;</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">	</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;openai==0.28&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In this guide, we&#x27;ll utilize ChatGPT to create our training dataset. To leverage Hugging Face and OpenAI resources, we first sign into these platforms using the commands below:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockTitle_Ktv7">Setting up credential keys</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Import libaries</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> huggingface_hub </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> login</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> openai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Setting up credential keys</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">OPENAI_KEY_FILE </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;YOUR_KEY_HERE&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">HUGGINGFACE_KEY_FILE </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;YOUR_KEY_HERE&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">openai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">api_key </span><span class="token operator">=</span><span class="token plain"> open_file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">OPENAI_KEY_FILE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">login</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">token</span><span class="token operator">=</span><span class="token plain">HUGGINGFACE_KEY_FILE</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-data-generation"><strong>2. Data generation</strong><a href="#2-data-generation" class="hash-link" aria-label="Direct link to 2-data-generation" title="Direct link to 2-data-generation">​</a></h2>
<p>In this tutorial, the “data” we will use will be the <a href="https://nitro.jan.ai/" target="_blank" rel="noopener noreferrer">Nitro documentation</a>. Nitro is an open-source, lightweight (3 MB) inference server to supercharge apps with local AI.</p>
<p><img decoding="async" loading="lazy" alt="About Nitro" src="/assets/images/about-nitro-77d4d2ab8a69afbe7c249c9c617db8a6.png" width="987" height="882" class="img_ev3q"></p>
<p><strong>Fig 1. Example of Nitro&#x27;s documentation.</strong></p>
<p>At a basic level, documentation is just pages filled with just words. If we give these words to the LLM as they are, it can confuse the model about what is important. Moreover, the unstructured nature of plain text doesn&#x27;t provide the contextual clues that LLMs need to understand and generate meaningful responses.</p>
<p>To teach it, we will use a method called <a href="#what-is-instruction-tuning"><strong>&quot;Instruction tuning&quot;</strong></a>, which involves refining the model&#x27;s ability to comprehend and execute text-based instructions more effectively.</p>
<p>But how do we change the text from the documentation into the right data? We need to make pairs of questions and answers.</p>
<p>The main idea is that we will break the documents into smaller pieces. Then, we use the LLM to help us develop questions and answers from those pieces.</p>
<p><em>Note: We also open-source the <a href="https://huggingface.co/datasets/jan-hq/nitro_binarized" target="_blank" rel="noopener noreferrer"><strong>Nitro’s documentation training dataset</strong></a> in our <a href="https://huggingface.co/jan-hq" target="_blank" rel="noopener noreferrer"><strong>Hugging Face Hub</strong></a>.</em></p>
<p><strong>Table 1. Example of Question and Answer pairs</strong></p>
<table><thead><tr><th>User</th><th>Assistant</th></tr></thead><tbody><tr><td>Is Nitro an open-source tool?</td><td>Yes, Nitro is an open-source tool.</td></tr><tr><td>What does the <code>max_tokens</code> parameter in the prompt request do?</td><td>The <code>max_tokens</code> parameter in the prompt request is used to specify the maximum number of tokens that the response should contain. A token can be as small as one character or as large as one word. For example, if <code>max_tokens</code> is set to 100, the response will contain no more than 100 tokens.</td></tr><tr><td>What operating systems does the Nitro library support?</td><td>The Nitro library supports multiple operating systems including Windows, MacOS, and Linux. This cross-platform compatibility allows it to cater to a wide range of users using different OS.</td></tr><tr><td>Is Nitro compatible with OpenAI?</td><td>Yes, Nitro is compatible with OpenAI. This means that it can work seamlessly with models and applications built using OpenAI&#x27;s technology.</td></tr><tr><td>What is the endpoint &#x27;/v1/chat/completions&#x27; used for in the curl command?</td><td>The &#x27;/v1/chat/completions&#x27; endpoint in the curl command is the specific location in the server where the request is being sent. The purpose of this endpoint is to handle chat completions, likely returning the next predicted response(s) from the chat assistant based on the sent message.</td></tr></tbody></table>
<p>You can create your dataset by using the following example code.</p>
<p>First, we need to define some helper functions to process the raw documents into QnA pairs.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockTitle_Ktv7">Define helper functions</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Reads and returns the content of a file.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">read_file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">filepath</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">open</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">filepath</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;r&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> encoding</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;utf-8&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">read</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Generates a response from the ChatGPT model</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">generate_chatgpt_response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">messages</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> temperature</span><span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> model</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;gpt-3.5-turbo&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> max_tokens</span><span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    response </span><span class="token operator">=</span><span class="token plain"> openai</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ChatCompletion</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">create</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        model</span><span class="token operator">=</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> messages</span><span class="token operator">=</span><span class="token plain">messages</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> temperature</span><span class="token operator">=</span><span class="token plain">temperature</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> max_tokens</span><span class="token operator">=</span><span class="token plain">max_tokens</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;choices&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;message&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;content&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Process Markdown files</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">process_markdown_file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">file_path</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> markdown_splitter</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> text_splitter</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">open</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">file_path</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;r&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        markdown_document </span><span class="token operator">=</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">read</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    md_header_splits </span><span class="token operator">=</span><span class="token plain"> markdown_splitter</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">split_text</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">markdown_document</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">chunk </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> split </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> md_header_splits </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> chunk </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> text_splitter</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">split_documents</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">split</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Extracts question and answer pairs from a given text</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">extract_qa_pairs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">text</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    qa_pairs </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    current_pair </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    lines </span><span class="token operator">=</span><span class="token plain"> text</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">split</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;\n&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> line </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> lines</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> line</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">startswith</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;&quot;question&quot;: &#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            current_pair</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;question&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> line</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">split</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;&quot;question&quot;: &#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">strip</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27; &quot;,&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">elif</span><span class="token plain"> line</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">startswith</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;&quot;answer&quot;: &#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            current_pair</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;answer&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> line</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">split</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;&quot;answer&quot;: &#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">strip</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27; &quot;,&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            qa_pairs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">append</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">current_pair</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            current_pair </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> qa_pairs</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Parse QnA pairs as JSON</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">parse_response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">try</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        parsed_data </span><span class="token operator">=</span><span class="token plain"> json</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">loads</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> parsed_data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;qa_pairs&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">except</span><span class="token plain"> json</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">JSONDecodeError</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> extract_qa_pairs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Create new column in the dataset</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">create_message</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">row</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> row</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;question&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;role&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;user&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;content&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> row</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;answer&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;role&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;assistant&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In this case, we&#x27;re using the Langchain framework to streamline our work, which gives us different ways to handle the processing step with just a few lines of code. Most of our documents are written in a Markdown format, so we&#x27;ll use the <code>MarkdownHeaderTextSplitter</code> function combined with the <code>TokenTextSplitter</code> function to ensure we give the LLM the right amount of text to create questions and answers.</p>
<p>We chose a chunk size of 300 tokens to ensure that when we generate QnA pairs, the generation won&#x27;t be out of context with the token length of the LLM (normally, it’s capped at 4096 tokens). Also, we applied the overlap technique so that each chunk will contain the context from the previous chunk to make the chunk coherent.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockTitle_Ktv7">Create logic for processing raw data</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Chunking settings</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">HEADERS_TO_SPLIT_ON </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;#&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Header 1&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;##&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Header 2&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;###&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Header 3&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Main Script Logic</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">markdown_splitter </span><span class="token operator">=</span><span class="token plain"> MarkdownHeaderTextSplitter</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">headers_to_split_on</span><span class="token operator">=</span><span class="token plain">HEADERS_TO_SPLIT_ON</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">text_splitter </span><span class="token operator">=</span><span class="token plain"> TokenTextSplitter</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">chunk_size</span><span class="token operator">=</span><span class="token number">300</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> chunk_overlap</span><span class="token operator">=</span><span class="token number">30</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>For generating QnA pairs, we need to set up the prompt for the LLM to generate the model. For this task, we used GPT-4 to generate QnA pairs but you can also try with any other Local LLMs with a little bit of tweaking on the system prompt.</p>
<div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">You are a curious assistant. Your task is to make 10 pairs of questions and answers using the given context delimited by triple quotation marks. You are extremely critical and can ask questions at different difficulty levels. You will be more generic and unique and focus on the Nitro library (the given context is from Nitro library). And you can also answer with the code block. Your `answer` must be detailed, comprehensive and step by step guide. Let&#x27;s think step by step. It&#x27;s really important to my project. Strictly follow the JSON format for output with 1 field `qa_pairs` and `question`, `answer`.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>To generate a diverse dataset, we&#x27;ll configure the LLM to produce 10 QnA pairs per iteration. We&#x27;ll execute this process three times to enrich the dataset&#x27;s variety. After setting everything up, let&#x27;s generate a training dataset.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Set up directory</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ROOT_DIR </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;PATH/TO/YOUR/DATA/FOLDER&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CSV_FILE_PATH </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;PATH/TO/SAVE/OUTPUT/CSV/FILE&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">REPO_NAME </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;YOUR/HUGGINGFACE/REPO&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Initialize data frame</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">all_chunks </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">master_df </span><span class="token operator">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">DataFrame</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">columns</span><span class="token operator">=</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;question&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;answer&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;raw&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Split raw text into chunks</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> subdir</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> dirs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> files </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> os</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">walk</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">ROOT_DIR</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">file</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> files</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">endswith</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;.md&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_path </span><span class="token operator">=</span><span class="token plain"> os</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">path</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">join</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">subdir</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            file_chunks </span><span class="token operator">=</span><span class="token plain"> process_markdown_file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">file_path</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">																								markdown_splitter</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">																								text_splitter</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            all_chunks</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">extend</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">file_chunks</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Generating QnA pairs with GPT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> _ </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">range</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">for</span><span class="token plain"> chunk </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">in</span><span class="token plain"> all_chunks</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        conversation </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;role&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;system&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;content&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> open_file</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">SYSTEM_FILE_PATH</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;role&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;user&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;content&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">str</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">chunk</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        response_verification </span><span class="token operator">=</span><span class="token plain"> chatgpt_completion</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">conversation</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        qa_pairs </span><span class="token operator">=</span><span class="token plain"> extract_qa_pairs_from_response</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">response_verification</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        qa_df </span><span class="token operator">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">DataFrame</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">qa_pairs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        qa_df</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;raw&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">chunk</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> </span><span class="token builtin" style="color:rgb(189, 147, 249)">len</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">qa_df</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        master_df </span><span class="token operator">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">concat</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">master_df</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> qa_df</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> ignore_index</span><span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">master_df</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">to_csv</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CSV_FILE_PATH</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> index</span><span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> encoding</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;utf-8&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Deduplication</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">df </span><span class="token operator">=</span><span class="token plain"> pd</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">read_csv</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CSV_FILE_PATH</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">df_deduplicated </span><span class="token operator">=</span><span class="token plain"> df</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">drop_duplicates</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">df_deduplicated</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;messages&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> df_deduplicated</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">apply</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">create_message</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> axis</span><span class="token operator">=</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Convert data frame to Huggingface dataset format</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">messages </span><span class="token operator">=</span><span class="token plain"> df_deduplicated</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;message&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">tolist</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">rejected </span><span class="token operator">=</span><span class="token plain"> df_deduplicated</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;rejected&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">tolist</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hf_dataset </span><span class="token operator">=</span><span class="token plain"> Dataset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">from_dict</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;messages&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> messages</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;chosen&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> messages</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&#x27;rejected&#x27;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> rejected</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Split train and test</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">split_dataset </span><span class="token operator">=</span><span class="token plain"> hf_dataset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">train_test_split</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">test_size</span><span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Push to Hugging Face Hub</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">split_dataset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">push_to_hub</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">REPO_NAME</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Please refer to <strong>Table 1</strong> for samples of the generated dataset.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-finetuning"><strong>3. Finetuning</strong><a href="#3-finetuning" class="hash-link" aria-label="Direct link to 3-finetuning" title="Direct link to 3-finetuning">​</a></h2>
<p>We use the <a href="https://github.com/huggingface/alignment-handbook" target="_blank" rel="noopener noreferrer">alignment-handbook</a> from Hugging Face for the training code. This is a well-written library that explains in detail everything about finetuning LLMs. It also provides cutting-edge technology implementation like <a href="#what-is-lora">LORA/QLoRA</a> or <a href="#what-is-flash-attention">Flash Attention</a> for efficient training on customer GPUs.</p>
<p>For installing the alignment-handbook, please follow their <a href="https://github.com/huggingface/alignment-handbook?tab=readme-ov-file#installation-instructions" target="_blank" rel="noopener noreferrer">installation guide</a>.</p>
<p>In our training setup, we selected the <a href="https://huggingface.co/jan-hq/stealth-v1.3" target="_blank" rel="noopener noreferrer">Stealth v1.3</a> model as the foundation. We explored different configurations of LoRA/QLoRA, focusing on the parameters <code>r</code> and <code>alpha</code>. The <code>r</code> parameter, denoting the rank in low-rank adaptation, influences the model&#x27;s learning capacity and complexity, with higher values offering more flexibility at the risk of overfitting. The <code>alpha</code> parameter scales the adaptation&#x27;s effect, balancing new learning and existing knowledge retention. We found <code>r = 256</code> and <code>alpha = 512</code> to be effective settings. For more details, see our sample YAML configuration file.</p>
<p>For training the model after installing the repository, you can run the following command:</p>
<div class="language-js codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockTitle_Ktv7">Command to train LLM with alignment handbook</div><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-js codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token constant" style="color:rgb(189, 147, 249)">ACCELERATE_LOG_LEVEL</span><span class="token operator">=</span><span class="token plain">info \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">accelerate launch \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token operator">--</span><span class="token plain">config_file recipes</span><span class="token operator">/</span><span class="token plain">accelerate_configs</span><span class="token operator">/</span><span class="token plain">multi_gpu</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">yaml \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token operator">--</span><span class="token plain">num_processes</span><span class="token operator">=</span><span class="token number">1</span><span class="token plain"> \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  scripts</span><span class="token operator">/</span><span class="token plain">run_sft</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">py recipes</span><span class="token operator">/</span><span class="token plain">nitro</span><span class="token operator">/</span><span class="token plain">sft</span><span class="token operator">/</span><span class="token plain">config_lora</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p><strong>Table 2. Training result of Nitro models.</strong></p>
<table><thead><tr><th>Model</th><th>r</th><th>alpha</th><th>Loss</th><th>Time</th></tr></thead><tbody><tr><td>Nitro E1 LoRA</td><td>16</td><td>32</td><td>1.185</td><td>3m</td></tr><tr><td>Nitro E3 LoRA</td><td>16</td><td>32</td><td>0.853</td><td>10m</td></tr><tr><td>Nitro E1 QLoRA</td><td>256</td><td>512</td><td>0.6513</td><td>6m</td></tr><tr><td>Nitro E3 QLoRA</td><td>256</td><td>512</td><td>0.3123</td><td>18m</td></tr></tbody></table>
<p><em>E: epochs, m: minutes</em>
<em>Note: Training times can vary based on hardware specifications. The provided times are for reference purposes only.</em></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-test-the-model"><strong>4. Test the model</strong><a href="#4-test-the-model" class="hash-link" aria-label="Direct link to 4-test-the-model" title="Direct link to 4-test-the-model">​</a></h2>
<p>After training the model, it can be tested locally in the GGUF format using <a href="https://jan.ai/" target="_blank" rel="noopener noreferrer">Jan</a>. To convert the fine-tuned model to GGUF, you can utilize this convenient <a href="https://colab.research.google.com/github/mlabonne/llm-course/blob/main/Quantize_Llama_2_models_using_GGUF_and_llama_cpp.ipynb" target="_blank" rel="noopener noreferrer">Google Colab notebook by Maxime Labonne</a>.</p>
<p><img decoding="async" loading="lazy" alt="Finetuned Nitro Respond" src="/assets/images/finetuned-response-f85b89b18e2705073f0632e6cd87183a.png" width="719" height="385" class="img_ev3q"></p>
<p><strong>Fig 2. Using Jan to run a new fine-tuned model.</strong></p>
<p><img decoding="async" loading="lazy" alt="Finetuned Nitro Respond 2" src="/assets/images/finetuned-respond-2-3bebfa561e4471585b412e14d605ab7a.png" width="645" height="769" class="img_ev3q"></p>
<p><strong>Fig 3. Model answers a technical question related to Nitro.</strong></p>
<p>As shown in <code>Fig 2</code>, the model successfully learned new information from Nitro&#x27;s documentation. This indicates that it accurately understands details about Nitro.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="limitations">Limitations<a href="#limitations" class="hash-link" aria-label="Direct link to Limitations" title="Direct link to Limitations">​</a></h2>
<p>With this straightforward approach, we show that the model is capable of acquiring new knowledge. However, there&#x27;s a potential risk of <a href="https://en.wikipedia.org/wiki/Catastrophic_interference" target="_blank" rel="noopener noreferrer">catastrophic forgetting</a>, leading to the model only being good at answering information about Nitro documentation and losing some other abilities.</p>
<p>In our next blog post, we will further discuss this problem and its solution.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusions"><strong>Conclusions</strong><a href="#conclusions" class="hash-link" aria-label="Direct link to conclusions" title="Direct link to conclusions">​</a></h2>
<p>In the blog post, we learn how to fine-tune an open-source model using LoRA/QLoRA with documentation of Nitro’s repository on a local machine. We’ve learned:</p>
<ul>
<li>Data generation using LangChain to chunk the documentation and use LLM to make QnA pairs from unstructured data.</li>
<li>Finetuning the model on generated data using QLoRA with high r and alpha setting.</li>
<li>Test the model using Jan.</li>
</ul>
<p>Combining all those steps, we can train our model on every documentation to create our chatbot.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="terminology">Terminology<a href="#terminology" class="hash-link" aria-label="Direct link to Terminology" title="Direct link to Terminology">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-instruction-tuning">What is Instruction tuning?<a href="#what-is-instruction-tuning" class="hash-link" aria-label="Direct link to What is Instruction tuning?" title="Direct link to What is Instruction tuning?">​</a></h3>
<p><a href="https://openai.com/research/instruction-following" target="_blank" rel="noopener noreferrer">Instruction tuning</a> in LLMs involves refining the model&#x27;s ability to comprehend and execute text-based instructions more effectively. By training on a diverse set of tasks presented as instructions, the model learns to generalize and apply its knowledge across a wide range of requests, enhancing its responsiveness and accuracy in fulfilling user commands. This process fine-tunes the model on a curated dataset where the inputs are explicit instructions and the desired outputs are model-generated responses, leading to improved performance on instruction-following tasks and a better alignment with user expectations.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-lora">What is LoRA?<a href="#what-is-lora" class="hash-link" aria-label="Direct link to What is LoRA?" title="Direct link to What is LoRA?">​</a></h3>
<p><a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">Low-Rank Adaptation</a> (LoRA) is a method that makes fine-tuning large language models more efficient. It breaks down the model&#x27;s large weight matrices into smaller, trainable matrices. These smaller matrices are the only parts that get updated, leaving the original weights unchanged. This approach significantly reduces the number of parameters that need training, leading to faster and less memory-intensive tuning. Essentially, LoRA is a new way of training LLMs with limited resources but with a little trade-off in performance.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-langchain">What is Langchain?<a href="#what-is-langchain" class="hash-link" aria-label="Direct link to What is Langchain?" title="Direct link to What is Langchain?">​</a></h3>
<p><a href="https://www.langchain.com/" target="_blank" rel="noopener noreferrer">LangChain</a> is an open-source framework designed to simplify the creation of applications powered by large language models (LLMs), such as chatbots and agents. Exactly like its name, it&#x27;s a chaining language for developers to easily apply advanced prompt techniques to get the most out of it. It also provides developers with a standardized interface and pre-built components, making advanced language understanding and generation more accessible. By abstracting the complexities of LLM integration, LangChain enables the rapid development of intelligent, context-aware applications. Its collaborative ecosystem encourages innovation, leveraging the community&#x27;s collective expertise to expand the possibilities of AI-driven solutions.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-flash-attention">What is Flash Attention?<a href="#what-is-flash-attention" class="hash-link" aria-label="Direct link to What is Flash Attention?" title="Direct link to What is Flash Attention?">​</a></h3>
<p><a href="https://github.com/Dao-AILab/flash-attention" target="_blank" rel="noopener noreferrer">Flash Attention</a> is an algorithm that speeds up the core attention mechanism in Transformer language models by restructuring computations. It uses techniques like tiling and recomputation to reduce the high memory costs of attention, enabling models to process longer text sequences.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/large-language-models/">Large Language Models</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/finetune-llm/">Finetune LLM</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/retrieval-augmented-generation/">Retrieval Augmented Generation</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/personal-dataset/">Personal Dataset</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/customzied-dataset/">Customzied Dataset</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/fine-tuning-tutorial/">Fine Tuning Tutorial</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/janhq/docs/tree/main/docs/pending-content/blogpost/finetune-with-docs.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2024-04-02T03:15:06.000Z">Apr 2, 2024</time></b> by <b>Nicole Zhu</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-environment-setup" class="table-of-contents__link toc-highlight">1. Environment setup</a></li><li><a href="#2-data-generation" class="table-of-contents__link toc-highlight"><strong>2. Data generation</strong></a></li><li><a href="#3-finetuning" class="table-of-contents__link toc-highlight"><strong>3. Finetuning</strong></a></li><li><a href="#4-test-the-model" class="table-of-contents__link toc-highlight"><strong>4. Test the model</strong></a></li><li><a href="#limitations" class="table-of-contents__link toc-highlight">Limitations</a></li><li><a href="#conclusions" class="table-of-contents__link toc-highlight"><strong>Conclusions</strong></a></li><li><a href="#terminology" class="table-of-contents__link toc-highlight">Terminology</a><ul><li><a href="#what-is-instruction-tuning" class="table-of-contents__link toc-highlight">What is Instruction tuning?</a></li><li><a href="#what-is-lora" class="table-of-contents__link toc-highlight">What is LoRA?</a></li><li><a href="#what-is-langchain" class="table-of-contents__link toc-highlight">What is Langchain?</a></li><li><a href="#what-is-flash-attention" class="table-of-contents__link toc-highlight">What is Flash Attention?</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="flex-shrink-0 relative overflow-hidden py-10"><div class="container"><div class="grid grid-cols-2 gap-8 md:grid-cols-2 lg:grid-cols-6"><div class="col-span-2"><div class="flex items-center space-x-2 mb-3"><img alt="Jan Logo" src="/img/logo.svg"><h2 class="h5">Jan</h2></div><div class="w-full lg:w-3/4 mt-2"><h6>The Soul of a New Machine</h6><p class="dark:text-gray-400 text-gray-600 mt-2">Subscribe to our newsletter on AI<!-- --> <br class="hidden lg:block">research and building Jan:</p><div class="mt-4"><form class="relative"><input type="email" class="w-full h-12 p-4 pr-14 rounded-xl border dark:border-gray-600 dark:bg-[#252525] border-[#F0F0F0]" placeholder="Enter your email" name="email"><button type="submit" class="absolute flex p-2 bg-black dark:bg-[#3B3B3C] w-8 h-8 border dark:border-gray-600 rounded-lg top-1/2 right-3 -translate-y-1/2"><svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" clip-rule="evenodd" d="M6.09026 8.41933L3.72077 7.62985C1.24061 6.80348 0 6.3903 0 5.63033C0 4.87142 1.24061 4.45718 3.72077 3.63081L12.6938 0.639442C14.4393 0.0576106 15.3121 -0.233305 15.7727 0.227312C16.2333 0.687928 15.9424 1.56068 15.3616 3.30512L12.3692 12.2792C11.5428 14.7594 11.1296 16 10.3697 16C9.61076 16 9.19652 14.7594 8.37015 12.2792L7.57962 9.9108L12.1689 5.3215C12.3609 5.1227 12.4672 4.85645 12.4648 4.58008C12.4624 4.30372 12.3515 4.03935 12.1561 3.84392C11.9607 3.64849 11.6963 3.53764 11.4199 3.53524C11.1435 3.53284 10.8773 3.63908 10.6785 3.83108L6.09026 8.41933Z" fill="white"></path></svg></button></form></div></div></div><div class="lg:text-right"><h2 class="mb-3 h6">Product</h2><ul><li><a href="/download" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Download</a></li><li><a href="/developer" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Documentation</a></li><li><a href="https://github.com/janhq/jan/releases" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Changelog</a></li></ul></div><div class="lg:text-right"><h2 class="mb-3 h6">For Developers</h2><ul><li><a href="/guides" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Guides</a></li><li><a href="/developer" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Developer</a></li><li><a href="/api-reference" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">API Reference</a></li></ul></div><div class="lg:text-right"><h2 class="mb-3 h6">Community</h2><ul><li><a href="https://github.com/janhq/jan" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Github</a></li><li><a href="https://discord.gg/FTk2MvZwJH" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Discord</a></li><li><a href="https://twitter.com/janframework" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Twitter</a></li><li><a href="https://www.linkedin.com/company/janframework/" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">LinkedIn</a></li></ul></div><div class="lg:text-right"><h2 class="mb-3 h6">Company</h2><ul><li><a href="/about" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">About</a></li><li><a href="/blog" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Blog</a></li><li><a href="https://janai.bamboohr.com/careers" target="_blank" class="inline-block py-1 dark:text-gray-400 text-gray-600">Careers</a></li><li><a href="/community#newsletter" target="_self" class="inline-block py-1 dark:text-gray-400 text-gray-600">Newsletter</a></li></ul></div></div></div><div class="container mt-8"><div class="flex w-full justify-between items-center"><span class="dark:text-gray-300 text-gray-700">©<!-- -->2024<!-- --> Jan AI Pte Ltd.</span><div class="flex items-center gap-x-3"><a aria-label="social-0" href="https://twitter.com/janframework" target="_blank" rel="noopener"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="text-xl text-black/60 dark:text-white/60" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M928 254.3c-30.6 13.2-63.9 22.7-98.2 26.4a170.1 170.1 0 0 0 75-94 336.64 336.64 0 0 1-108.2 41.2A170.1 170.1 0 0 0 672 174c-94.5 0-170.5 76.6-170.5 170.6 0 13.2 1.6 26.4 4.2 39.1-141.5-7.4-267.7-75-351.6-178.5a169.32 169.32 0 0 0-23.2 86.1c0 59.2 30.1 111.4 76 142.1a172 172 0 0 1-77.1-21.7v2.1c0 82.9 58.6 151.6 136.7 167.4a180.6 180.6 0 0 1-44.9 5.8c-11.1 0-21.6-1.1-32.2-2.6C211 652 273.9 701.1 348.8 702.7c-58.6 45.9-132 72.9-211.7 72.9-14.3 0-27.5-.5-41.2-2.1C171.5 822 261.2 850 357.8 850 671.4 850 843 590.2 843 364.7c0-7.4 0-14.8-.5-22.2 33.2-24.3 62.3-54.4 85.5-88.2z"></path></svg></a><a aria-label="social-1" href="https://discord.com/invite/FTk2MvZwJH" target="_blank" rel="noopener"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl text-black/60 dark:text-white/60" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M14.82 4.26a10.14 10.14 0 0 0-.53 1.1 14.66 14.66 0 0 0-4.58 0 10.14 10.14 0 0 0-.53-1.1 16 16 0 0 0-4.13 1.3 17.33 17.33 0 0 0-3 11.59 16.6 16.6 0 0 0 5.07 2.59A12.89 12.89 0 0 0 8.23 18a9.65 9.65 0 0 1-1.71-.83 3.39 3.39 0 0 0 .42-.33 11.66 11.66 0 0 0 10.12 0q.21.18.42.33a10.84 10.84 0 0 1-1.71.84 12.41 12.41 0 0 0 1.08 1.78 16.44 16.44 0 0 0 5.06-2.59 17.22 17.22 0 0 0-3-11.59 16.09 16.09 0 0 0-4.09-1.35zM8.68 14.81a1.94 1.94 0 0 1-1.8-2 1.93 1.93 0 0 1 1.8-2 1.93 1.93 0 0 1 1.8 2 1.93 1.93 0 0 1-1.8 2zm6.64 0a1.94 1.94 0 0 1-1.8-2 1.93 1.93 0 0 1 1.8-2 1.92 1.92 0 0 1 1.8 2 1.92 1.92 0 0 1-1.8 2z"></path></svg></a><a aria-label="social-2" href="https://github.com/janhq/jan" target="_blank" rel="noopener"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" class="text-lg text-black/60 dark:text-white/60" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M511.6 76.3C264.3 76.2 64 276.4 64 523.5 64 718.9 189.3 885 363.8 946c23.5 5.9 19.9-10.8 19.9-22.2v-77.5c-135.7 15.9-141.2-73.9-150.3-88.9C215 726 171.5 718 184.5 703c30.9-15.9 62.4 4 98.9 57.9 26.4 39.1 77.9 32.5 104 26 5.7-23.5 17.9-44.5 34.7-60.8-140.6-25.2-199.2-111-199.2-213 0-49.5 16.3-95 48.3-131.7-20.4-60.5 1.9-112.3 4.9-120 58.1-5.2 118.5 41.6 123.2 45.3 33-8.9 70.7-13.6 112.9-13.6 42.4 0 80.2 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.3-43.9 2.9 7.7 24.7 58.3 5.5 118 32.4 36.8 48.9 82.7 48.9 132.3 0 102.2-59 188.1-200 212.9a127.5 127.5 0 0 1 38.1 91v112.5c.8 9 0 17.9 15 17.9 177.1-59.7 304.6-227 304.6-424.1 0-247.2-200.4-447.3-447.5-447.3z"></path></svg></a><a aria-label="social-3" href="https://www.linkedin.com/company/janframework/" target="_blank" rel="noopener"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" class="text-xl text-black/60 dark:text-white/60" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><circle cx="4.983" cy="5.009" r="2.188"></circle><path d="M9.237 8.855v12.139h3.769v-6.003c0-1.584.298-3.118 2.262-3.118 1.937 0 1.961 1.811 1.961 3.218v5.904H21v-6.657c0-3.27-.704-5.783-4.526-5.783-1.835 0-3.065 1.007-3.568 1.96h-.051v-1.66H9.237zm-6.142 0H6.87v12.139H3.095z"></path></svg></a></div></div></div></footer></div>
</body>
</html>